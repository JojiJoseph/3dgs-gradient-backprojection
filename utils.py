from dataclasses import is_dataclass
from enum import Enum
import os
from pathlib import Path
import cv2
import torch
import pycolmap_scene_manager as pycolmap
from typing import Any, Literal, Optional
import numpy as np
from gsplat import rasterization
import warnings
from plyfile import PlyData
import json
from rich.console import Console
from rich.table import Table



def _detach_tensors_from_dict(d, inplace=True):
    if not inplace:
        d = d.copy()
    for key in d:
        if isinstance(d[key], torch.Tensor):
            d[key] = d[key].detach()
    return d


def load_checkpoint(
    checkpoint: str,
    data_dir: str,
    format: Literal["inria", "gsplat", "ply"] = "gsplat",
    data_factor: int = 1,
    rasterizer: Optional[Literal["inria", "gsplat"]] = None,
):

    colmap_project = pycolmap.SceneManager(f"{data_dir}/sparse/0")
    colmap_project.load_cameras()
    colmap_project.load_images()
    colmap_project.load_points3D()
    if format in ["inria", "gsplat"]:
        model = torch.load(checkpoint,weights_only=False)  # Make sure it is generated by 3DGS original repo

    if format is None:
        if rasterizer is None:
            raise ValueError("Must specify format or rasterizer")
        else:
            format = rasterizer
    if rasterizer is not None:
        format = rasterizer
        warnings.warn(
            "`rasterizer` is deprecated. Use `format` instead.", DeprecationWarning
        )
    if format == "inria":
        model_params, _ = model
        splats = {
            "active_sh_degree": model_params[0],
            "means": model_params[1],
            "features_dc": model_params[2],
            "features_rest": model_params[3],
            "scaling": model_params[4],
            "rotation": model_params[5],
            "opacity": model_params[6].squeeze(1),
        }
    elif format == "gsplat":

        model_params = model["splats"]
        splats = {
            "active_sh_degree": 3,
            "means": model_params["means"],
            "features_dc": model_params["sh0"],
            "features_rest": model_params["shN"],
            "scaling": model_params["scales"],
            "rotation": model_params["quats"],
            "opacity": model_params["opacities"],
        }
    elif format == "ply":
        plydata = PlyData.read(checkpoint)
        vertex = plydata['vertex'].data

        vertex_np = {name: vertex[name] for name in vertex.dtype.names}
        # print(vertex_np.keys())
        # print(vertex_np['nx'].min(), vertex_np['ny'].max(), vertex_np['ny'], vertex_np['nz'])
        # exit()

        def to_tensor(name, dtype=torch.float32):
            return torch.tensor(vertex_np[name], dtype=dtype)
        

        splats = {
            "active_sh_degree": 3,
            "means": torch.stack([to_tensor("x"), to_tensor("y"), to_tensor("z")], dim=1),
            "features_dc": torch.stack([to_tensor("f_dc_0"), to_tensor("f_dc_1"), to_tensor("f_dc_2")], dim=1).reshape((-1,1,3)),
            "features_rest": torch.stack(
                [to_tensor(f"f_rest_{i}") for i in range(45)], dim=1
            ).reshape((-1,15,3)),
            "scaling": torch.stack([to_tensor(f"scale_{i}") for i in range(3)], dim=1),
            "rotation": torch.stack([to_tensor(f"rot_{i}") for i in range(4)], dim=1),
            "opacity": to_tensor("opacity"),
        }

    else:
        raise ValueError("Invalid Gaussian splatting format")

    _detach_tensors_from_dict(splats)

    # Assuming only one camera
    for camera in colmap_project.cameras.values():
        camera_matrix = torch.tensor(
            [
                [camera.fx, 0, camera.cx],
                [0, camera.fy, camera.cy],
                [0, 0, 1],
            ]
        )
        break

    camera_matrix[:2, :3] /= data_factor

    splats["camera_matrix"] = camera_matrix
    splats["colmap_project"] = colmap_project
    splats["colmap_dir"] = data_dir

    return splats

def load_checkpoint_f3dgs(
    checkpoint: str,
    data_dir: str,
    format: Literal["inria", "gsplat"] = "gsplat",
    data_factor: int = 1,
    rasterizer: Optional[Literal["inria", "gsplat"]] = None,
):
    # Currently supports only gsplat format
    colmap_project = pycolmap.SceneManager(f"{data_dir}/sparse/0")
    colmap_project.load_cameras()
    colmap_project.load_images()
    colmap_project.load_points3D()
    model = torch.load(checkpoint)  # Make sure it is generated by 3DGS original repo

    if format is None:
        if rasterizer is None:
            raise ValueError("Must specify format or rasterizer")
        else:
            format = rasterizer
    if rasterizer is not None:
        format = rasterizer
        warnings.warn(
            "`rasterizer` is deprecated. Use `format` instead.", DeprecationWarning
        )
    if format == "inria":
        model_params, _ = model
        splats = {
            "active_sh_degree": model_params[0],
            "means": model_params[1],
            "features_dc": model_params[2],
            "features_rest": model_params[3],
            "scaling": model_params[4],
            "rotation": model_params[5],
            "opacity": model_params[6].squeeze(1),
        }
    elif format == "gsplat":

        model_params = model["splats"]
        splats = {
            "active_sh_degree": 3,
            "means": model_params["means"],
            "features_dc": model_params["sh0"],
            "features_rest": model_params["shN"],
            "scaling": model_params["scales"],
            "rotation": model_params["quats"],
            "opacity": model_params["opacities"],
            "conv": model_params["conv"],
            "features": model_params["features"],
        }
    else:
        raise ValueError("Invalid Gaussian splatting format")

    _detach_tensors_from_dict(splats)

    # Assuming only one camera
    for camera in colmap_project.cameras.values():
        camera_matrix = torch.tensor(
            [
                [camera.fx, 0, camera.cx],
                [0, camera.fy, camera.cy],
                [0, 0, 1],
            ]
        )
        break

    camera_matrix[:2, :3] /= data_factor

    splats["camera_matrix"] = camera_matrix
    splats["colmap_project"] = colmap_project
    splats["colmap_dir"] = data_dir

    return splats


def get_rpy_matrix(roll, pitch, yaw):
    roll_matrix = np.array(
        [
            [1, 0, 0, 0],
            [0, np.cos(roll), -np.sin(roll), 0],
            [0, np.sin(roll), np.cos(roll), 0],
            [0, 0, 0, 1.0],
        ]
    )

    pitch_matrix = np.array(
        [
            [np.cos(pitch), 0, np.sin(pitch), 0],
            [0, 1, 0, 0],
            [-np.sin(pitch), 0, np.cos(pitch), 0],
            [0, 0, 0, 1.0],
        ]
    )
    yaw_matrix = np.array(
        [
            [np.cos(yaw), -np.sin(yaw), 0, 0],
            [np.sin(yaw), np.cos(yaw), 0, 0],
            [0, 0, 1, 0],
            [0, 0, 0, 1.0],
        ]
    )

    return yaw_matrix @ pitch_matrix @ roll_matrix


def get_viewmat_from_colmap_image(image):
    viewmat = torch.eye(4).float()  # .to(device)
    viewmat[:3, :3] = torch.tensor(image.R()).float()  # .to(device)
    viewmat[:3, 3] = torch.tensor(image.t).float()  # .to(device)
    return viewmat

def get_viewmat_from_blender_frame(frame):
    # Convert Blender frame to view matrix
    c2w_blender = torch.tensor(frame["transform_matrix"]).float()
    c2w = c2w_blender.clone()
    c2w[:3, :3] = c2w_blender[:3, :3] @ torch.tensor(([1, 0, 0], [0, -1, 0], [0, 0, -1])).float()
    viewmat = torch.linalg.inv(c2w)  # Convert to camera-to-world matrix
    return viewmat


def prune_by_gradients(splats, return_mask=False):
    colmap_project = splats["colmap_project"]
    frame_idx = 0
    means = splats["means"]
    colors_dc = splats["features_dc"]
    colors_rest = splats["features_rest"]
    colors = torch.cat([colors_dc, colors_rest], dim=1)
    opacities = torch.sigmoid(splats["opacity"])
    scales = torch.exp(splats["scaling"])
    quats = splats["rotation"]

    K = splats["camera_matrix"]
    colors.requires_grad = True
    gaussian_grads = torch.zeros(colors.shape[0], device=colors.device)
    for image in sorted(colmap_project.images.values(), key=lambda x: x.name):
        viewmat = get_viewmat_from_colmap_image(image)
        output, _, _ = rasterization(
            means,
            quats,
            scales,
            opacities,
            colors[:, 0, :],
            viewmats=viewmat[None],
            Ks=K[None],
            # sh_degree=3,
            width=K[0, 2] * 2,
            height=K[1, 2] * 2,
        )
        frame_idx += 1
        pseudo_loss = ((output.detach() + 1 - output) ** 2).mean()
        pseudo_loss.backward()
        # print(colors.grad.shape)
        gaussian_grads += (colors.grad[:, 0]).norm(dim=[1])
        colors.grad.zero_()

    mask = gaussian_grads > 0
    # console = Console()
    # table = Table(title="Pruning Report")
    # table.add_column("Metric", style="cyan", no_wrap=True)
    # table.add_column("Value", style="magenta")

    # table.add_row("Total splats", str(len(gaussian_grads)))
    # table.add_row("Pruned splats", str((~mask).sum().item()))
    # table.add_row("Remaining splats", str(mask.sum().item()))

    # console.print(table)
    splats = splats.copy()
    splats["means"] = splats["means"][mask]
    splats["features_dc"] = splats["features_dc"][mask]
    splats["features_rest"] = splats["features_rest"][mask]
    splats["scaling"] = splats["scaling"][mask]
    splats["rotation"] = splats["rotation"][mask]
    splats["opacity"] = splats["opacity"][mask]
    if "features" in splats:
        splats["features"] = splats["features"][mask]

    if return_mask:
        return splats, mask
    
    return splats


def create_checkerboard(width, height, size=64):
    checkerboard = np.zeros((height, width, 3), dtype=np.uint8)
    for y in range(0, height, size):
        for x in range(0, width, size):
            if (x // size + y // size) % 2 == 0:
                checkerboard[y : y + size, x : x + size] = 255
            else:
                checkerboard[y : y + size, x : x + size] = 128
    return checkerboard


def torch_to_cv(tensor, permute=False):
    if permute:
        tensor = torch.clamp(tensor.permute(1, 2, 0), 0, 1).cpu().numpy()
    else:
        tensor = torch.clamp(tensor, 0, 1).cpu().numpy()
    return (tensor * 255).astype(np.uint8)[..., ::-1]

def test_proper_pruning(splats, splats_after_pruning):
    colmap_project = splats["colmap_project"]
    frame_idx = 0
    means = splats["means"]
    colors_dc = splats["features_dc"]
    colors_rest = splats["features_rest"]
    colors = torch.cat([colors_dc, colors_rest], dim=1)
    opacities = torch.sigmoid(splats["opacity"])
    scales = torch.exp(splats["scaling"])
    quats = splats["rotation"]

    means_pruned = splats_after_pruning["means"]
    colors_dc_pruned = splats_after_pruning["features_dc"]
    colors_rest_pruned = splats_after_pruning["features_rest"]
    colors_pruned = torch.cat([colors_dc_pruned, colors_rest_pruned], dim=1)
    opacities_pruned = torch.sigmoid(splats_after_pruning["opacity"])
    scales_pruned = torch.exp(splats_after_pruning["scaling"])
    quats_pruned = splats_after_pruning["rotation"]

    K = splats["camera_matrix"]
    total_error = 0
    max_pixel_error = 0
    for image in sorted(colmap_project.images.values(), key=lambda x: x.name):
        viewmat = get_viewmat_from_colmap_image(image)
        output, _, _ = rasterization(
            means,
            quats,
            scales,
            opacities,
            colors,
            viewmats=viewmat[None],
            Ks=K[None],
            sh_degree=3,
            width=K[0, 2] * 2,
            height=K[1, 2] * 2,
        )

        output_pruned, _, _ = rasterization(
            means_pruned,
            quats_pruned,
            scales_pruned,
            opacities_pruned,
            colors_pruned,
            viewmats=viewmat[None],
            Ks=K[None],
            sh_degree=3,
            width=K[0, 2] * 2,
            height=K[1, 2] * 2,
        )

        total_error += torch.abs((output - output_pruned)).sum()
        max_pixel_error = max(
            max_pixel_error, torch.abs((output - output_pruned)).max()
        )

    percentage_pruned = (
        (len(splats["means"]) - len(splats_after_pruning["means"]))
        / len(splats["means"])
        * 100
    )

    assert max_pixel_error < 1 / (
        255 * 2
    ), "Max pixel error should be less than 1/(255*2), safety margin"
    console = Console()
    table = Table(title="Pruning Report")
    table.add_column("Metric", style="cyan", no_wrap=True)
    table.add_column("Value", style="magenta")

    table.add_row("Percentage Pruned", f"{percentage_pruned:.2f}%")
    table.add_row("Max Pixel Error", f"{max_pixel_error:.6f}")
    table.add_row("Total Pixel Error", f"{total_error:.6f}")
    table.add_row("Original Splats", str(len(splats["means"])))
    table.add_row("Pruned Splats", str(len(splats["means"]) - len(splats_after_pruning["means"])))
    table.add_row("Remaining Splats", str(len(splats_after_pruning["means"])))

    console.print(table)

def load_checkpoint_blender(
    checkpoint: str,
    data_dir: str, # 
    format: Literal["inria", "gsplat", "ply"] = "gsplat",
    data_factor: int = 1,
    rasterizer: Optional[Literal["inria", "gsplat"]] = None,
):

    transforms = json.load(open(f"{data_dir}/transforms.json"))
    blender_img_dir = f"{data_dir}/images"

    if format in ["inria", "gsplat"]:
        model = torch.load(checkpoint,weights_only=False)  # Make sure it is generated by 3DGS original repo

    if format is None:
        if rasterizer is None:
            raise ValueError("Must specify format or rasterizer")
        else:
            format = rasterizer
    if rasterizer is not None:
        format = rasterizer
        warnings.warn(
            "`rasterizer` is deprecated. Use `format` instead.", DeprecationWarning
        )
    if format == "inria":
        model_params, _ = model
        splats = {
            "active_sh_degree": model_params[0],
            "means": model_params[1],
            "features_dc": model_params[2],
            "features_rest": model_params[3],
            "scaling": model_params[4],
            "rotation": model_params[5],
            "opacity": model_params[6].squeeze(1),
        }
    elif format == "gsplat":

        model_params = model["splats"]
        splats = {
            "active_sh_degree": 3,
            "means": model_params["means"],
            "features_dc": model_params["sh0"],
            "features_rest": model_params["shN"],
            "scaling": model_params["scales"],
            "rotation": model_params["quats"],
            "opacity": model_params["opacities"],
        }
    elif format == "ply":
        plydata = PlyData.read(checkpoint)
        vertex = plydata['vertex'].data

        vertex_np = {name: vertex[name] for name in vertex.dtype.names}
        # print(vertex_np.keys())
        # print(vertex_np['nx'].min(), vertex_np['ny'].max(), vertex_np['ny'], vertex_np['nz'])
        # exit()

        def to_tensor(name, dtype=torch.float32):
            return torch.tensor(vertex_np[name], dtype=dtype)
        

        splats = {
            "active_sh_degree": 3,
            "means": torch.stack([to_tensor("x"), to_tensor("y"), to_tensor("z")], dim=1),
            "features_dc": torch.stack([to_tensor("f_dc_0"), to_tensor("f_dc_1"), to_tensor("f_dc_2")], dim=1).reshape((-1,1,3)),
            "features_rest": torch.stack(
                [to_tensor(f"f_rest_{i}") for i in range(45)], dim=1
            ).reshape((-1,15,3)),
            "scaling": torch.stack([to_tensor(f"scale_{i}") for i in range(3)], dim=1),
            "rotation": torch.stack([to_tensor(f"rot_{i}") for i in range(4)], dim=1),
            "opacity": to_tensor("opacity"),
        }

    else:
        raise ValueError("Invalid Gaussian splatting format")

    _detach_tensors_from_dict(splats)

    splats["blender_img_dir"] = blender_img_dir
    splats["data_factor"] = data_factor
    splats["transforms"] = transforms
    fx = transforms["fl_x"]
    fy = transforms["fl_y"]
    cx = transforms["cx"]
    cy = transforms["cy"]

    camera_matrix = torch.tensor(
        [
            [fx / data_factor, 0, cx / data_factor],
            [0, fy / data_factor, cy / data_factor],
            [0, 0, 1],
        ],
        dtype=torch.float32,
    )

    width = int(camera_matrix[0, 2] * 2)
    height = int(camera_matrix[1, 2] * 2)
    splats["camera_matrix"] = camera_matrix

    return splats
def get_frames(colmap_project, interval=None, n_views=None, percentage_frames=100):
    """
    Returns a list of dictionaries containing image names and their corresponding view matrices,
    sorted by image name.
    """
    if interval is None:
        interval = max(len(colmap_project.images) // percentage_frames, 1)
    if n_views is not None:
        interval = max(len(colmap_project.images) // n_views, 1)
    images = sorted(colmap_project.images.values(), key=lambda img: img.name)
    frames = []
    for image in images[::interval]:
        frame = {
            "image_name": image.name,
            "viewmat": get_viewmat_from_colmap_image(image)
        }
        frames.append(frame)
    if n_views is not None:
        frames = frames[:n_views]
    return frames

def get_frames_blender(transforms, interval=None, n_views=None, percentage_frames=100):
    """
    Returns a list of dictionaries containing image names and their corresponding view matrices,
    sorted by image name.
    """
    if interval is not None and n_views is not None:
        raise ValueError("Cannot specify both interval and n_views")
    
    if interval is None:
        interval = max(len(transforms) // percentage_frames, 1)
    if n_views is not None:
        interval = max(len(transforms) // n_views, 1)
    frames = []

    for data in transforms["frames"][::interval]:
        frame = {
            "image_name": data["file_path"].split("/")[-1],
            "viewmat": get_viewmat_from_blender_frame(data),
            **data
        }
        frames.append(frame)
    if n_views is not None:
        frames = frames[:n_views]
    return frames

def get_frames(colmap_project, interval=None, n_views=None, percentage_frames=100):
    """
    Returns a list of dictionaries containing image names and their corresponding view matrices,
    sorted by image name.
    """
    if interval is not None and n_views is not None:
        raise ValueError("Cannot specify both interval and n_views")
    
    total_frames = int(percentage_frames / 100.0 * len(colmap_project.images))
    if interval is None:
        interval = max(len(colmap_project.images) // total_frames, 1)
    if n_views is not None:
        interval = max(len(colmap_project.images) // n_views, 1)
    images = sorted(colmap_project.images.values(), key=lambda img: img.name)
    frames = []
    for image in images[::interval]:
        frame = {
            "image_name": image.name,
            "viewmat": get_viewmat_from_colmap_image(image),
            "colmap_image": image, # For future use
        }
        frames.append(frame)
    if n_views is not None:
        frames = frames[:n_views]
    return frames

def get_frames_scannet(scannet_dir, interval=None, n_views=None, percentage_frames=100):
    """
    Returns a list of dictionaries containing image names and their corresponding view matrices,
    sorted by image name.
    """
    image_dir = os.path.join(scannet_dir, "output", "color")
    pose_dir = os.path.join(scannet_dir, "output", "pose")
    img_list = sorted(os.listdir(image_dir))
    img_list = [item for item in img_list if item.endswith(".jpg") or item.endswith(".png")]
    if interval is not None and n_views is not None:
        raise ValueError("Cannot specify both interval and n_views")

    total_frames = int(percentage_frames / 100.0 * len(img_list))
    if interval is None:
        interval = max(len(img_list) // total_frames, 1)
    if n_views is not None:
        interval = max(len(img_list) // n_views, 1)
    images = sorted(img_list)
    frames = []
    
    for image in images[::interval]:
        pose = np.loadtxt(os.path.join(pose_dir, f"{image[:-4]}.txt"))
        if np.isnan(pose).any():
            continue
        viewmat = torch.linalg.inv(torch.tensor(pose).float())
        # print(image)
        frame = {
            "image_name": image,
            "viewmat": viewmat,
            "colmap_image": image, # For future use
        }
        frames.append(frame)
    if n_views is not None:
        frames = frames[:n_views]
    return frames

def load_checkpoint_blender(
    checkpoint: str,
    data_dir: str, # 
    format: Literal["inria", "gsplat", "ply"] = "gsplat",
    data_factor: int = 1,
    rasterizer: Optional[Literal["inria", "gsplat"]] = None,
):

    transforms = json.load(open(f"{data_dir}/transforms.json"))
    blender_img_dir = f"{data_dir}/images"

    if format in ["inria", "gsplat"]:
        model = torch.load(checkpoint,weights_only=False)  # Make sure it is generated by 3DGS original repo

    if format is None:
        if rasterizer is None:
            raise ValueError("Must specify format or rasterizer")
        else:
            format = rasterizer
    if rasterizer is not None:
        format = rasterizer
        warnings.warn(
            "`rasterizer` is deprecated. Use `format` instead.", DeprecationWarning
        )
    if format == "inria":
        model_params, _ = model
        splats = {
            "active_sh_degree": model_params[0],
            "means": model_params[1],
            "features_dc": model_params[2],
            "features_rest": model_params[3],
            "scaling": model_params[4],
            "rotation": model_params[5],
            "opacity": model_params[6].squeeze(1),
        }
    elif format == "gsplat":

        model_params = model["splats"]
        splats = {
            "active_sh_degree": 3,
            "means": model_params["means"],
            "features_dc": model_params["sh0"],
            "features_rest": model_params["shN"],
            "scaling": model_params["scales"],
            "rotation": model_params["quats"],
            "opacity": model_params["opacities"],
        }
    elif format == "ply":
        plydata = PlyData.read(checkpoint)
        vertex = plydata['vertex'].data

        vertex_np = {name: vertex[name] for name in vertex.dtype.names}
        # print(vertex_np.keys())
        # print(vertex_np['nx'].min(), vertex_np['ny'].max(), vertex_np['ny'], vertex_np['nz'])
        # exit()

        def to_tensor(name, dtype=torch.float32):
            return torch.tensor(vertex_np[name], dtype=dtype)
        

        splats = {
            "active_sh_degree": 3,
            "means": torch.stack([to_tensor("x"), to_tensor("y"), to_tensor("z")], dim=1),
            "features_dc": torch.stack([to_tensor("f_dc_0"), to_tensor("f_dc_1"), to_tensor("f_dc_2")], dim=1).reshape((-1,1,3)),
            "features_rest": torch.stack(
                [to_tensor(f"f_rest_{i}") for i in range(45)], dim=1
            ).reshape((-1,15,3)),
            "scaling": torch.stack([to_tensor(f"scale_{i}") for i in range(3)], dim=1),
            "rotation": torch.stack([to_tensor(f"rot_{i}") for i in range(4)], dim=1),
            "opacity": to_tensor("opacity"),
        }

    else:
        raise ValueError("Invalid Gaussian splatting format")

    _detach_tensors_from_dict(splats)

    splats["blender_img_dir"] = blender_img_dir
    splats["data_factor"] = data_factor
    splats["transforms"] = transforms
    fx = transforms["fl_x"]
    fy = transforms["fl_y"]
    cx = transforms["cx"]
    cy = transforms["cy"]

    camera_matrix = torch.tensor(
        [
            [fx / data_factor, 0, cx / data_factor],
            [0, fy / data_factor, cy / data_factor],
            [0, 0, 1],
        ],
        dtype=torch.float32,
    )

    width = int(camera_matrix[0, 2] * 2)
    height = int(camera_matrix[1, 2] * 2)
    splats["camera_matrix"] = camera_matrix

    return splats

def load_checkpoint_scannet(
    checkpoint: str,
    data_dir: str, # 
    format: Literal["inria", "gsplat", "ply"] = "gsplat",
    data_factor: int = 1,
    rasterizer: Optional[Literal["inria", "gsplat"]] = None,
):

    # transforms = json.load(open(f"{data_dir}/transforms.json"))
    scannet_img_dir = f"{data_dir}/output/color"


    if format in ["inria", "gsplat"]:
        model = torch.load(checkpoint,weights_only=False)  # Make sure it is generated by 3DGS original repo

    if format is None:
        if rasterizer is None:
            raise ValueError("Must specify format or rasterizer")
        else:
            format = rasterizer
    if rasterizer is not None:
        format = rasterizer
        warnings.warn(
            "`rasterizer` is deprecated. Use `format` instead.", DeprecationWarning
        )
    if format == "inria":
        model_params, _ = model
        splats = {
            "active_sh_degree": model_params[0],
            "means": model_params[1],
            "features_dc": model_params[2],
            "features_rest": model_params[3],
            "scaling": model_params[4],
            "rotation": model_params[5],
            "opacity": model_params[6].squeeze(1),
        }
    elif format == "gsplat":

        model_params = model["splats"]
        splats = {
            "active_sh_degree": 3,
            "means": model_params["means"],
            "features_dc": model_params["sh0"],
            "features_rest": model_params["shN"],
            "scaling": model_params["scales"],
            "rotation": model_params["quats"],
            "opacity": model_params["opacities"],
        }
    elif format == "ply":
        plydata = PlyData.read(checkpoint)
        vertex = plydata['vertex'].data

        vertex_np = {name: vertex[name] for name in vertex.dtype.names}
        # print(vertex_np.keys())
        # print(vertex_np['nx'].min(), vertex_np['ny'].max(), vertex_np['ny'], vertex_np['nz'])
        # exit()

        def to_tensor(name, dtype=torch.float32):
            return torch.tensor(vertex_np[name], dtype=dtype)
        

        splats = {
            "active_sh_degree": 3,
            "means": torch.stack([to_tensor("x"), to_tensor("y"), to_tensor("z")], dim=1),
            "features_dc": torch.stack([to_tensor("f_dc_0"), to_tensor("f_dc_1"), to_tensor("f_dc_2")], dim=1).reshape((-1,1,3)),
            "features_rest": torch.stack(
                [to_tensor(f"f_rest_{i}") for i in range(45)], dim=1
            ).reshape((-1,15,3)),
            "scaling": torch.stack([to_tensor(f"scale_{i}") for i in range(3)], dim=1),
            "rotation": torch.stack([to_tensor(f"rot_{i}") for i in range(4)], dim=1),
            "opacity": to_tensor("opacity"),
        }


    else:
        raise ValueError("Invalid Gaussian splatting format")

    _detach_tensors_from_dict(splats)

    splats["scannet_path"] = data_dir
    splats["data_dir"] = data_dir
    splats["scannet_img_dir"] = scannet_img_dir
    splats["data_factor"] = data_factor
    # splats["transforms"] = transforms
    # fx = transforms["fl_x"]
    # fy = transforms["fl_y"]
    # cx = transforms["cx"]
    # cy = transforms["cy"]
    camera_matrix_path = f"{data_dir}/output/intrinsic/intrinsic_color.txt"
    camera_matrix = np.loadtxt(camera_matrix_path)
    fx = camera_matrix[0,0]
    fy = camera_matrix[1,1]
    cx = camera_matrix[0,2]
    cy = camera_matrix[1,2]

    sample_image = cv2.imread(f"{scannet_img_dir}/0.jpg")

    camera_matrix = torch.tensor(
        [
            [fx / data_factor, 0, cx / data_factor],
            [0, fy / data_factor, cy / data_factor],
            [0, 0, 1],
        ],
        dtype=torch.float32,
    )

    # width = int(camera_matrix[0, 2] * 2)
    # height = int(camera_matrix[1, 2] * 2)
    width = sample_image.shape[1] // data_factor
    height = sample_image.shape[0] // data_factor
    splats["camera_matrix"] = camera_matrix
    splats["width"] = width
    splats["height"] = height

    return splats

class FeatureRenderer:
    """
    Utility class for rasterizing features and colors with most parameters fixed.
    This class is designed to facilitate repeated rasterization operations where the majority of 
    parameters (such as means, quaternions, scales, opacities, colors, view matrices, camera intrinsics, 
    image dimensions, and features) are set once during initialization and reused for subsequent renders.
    Note:
        - The class stores references to the input torch.tensors, not clones. 
            Be cautious when modifying these tensors temporarily, as changes will affect the internal state 
            unless you explicitly clone the data before editing.
    Args:
        means (torch.Tensor, optional): Means of the splats.
        quats (torch.Tensor, optional): Quaternions representing orientations.
        scales (torch.Tensor, optional): Scale factors for splats.
        opacities (torch.Tensor, optional): Opacity values for splats.
        colors (torch.Tensor, optional): Color values for splats.
        viewmats (torch.Tensor, optional): Camera view matrices.
        Ks (torch.Tensor, optional): Camera intrinsic matrices.
        width (int, optional): Image width.
        height (int, optional): Image height.
        features (torch.Tensor, optional): Feature vectors for splats.
        sh_degree (int, optional): Spherical harmonics degree for color rendering.
    Methods:
        render(...): Rasterizes colors using the stored or provided parameters.
        render_features(...): Rasterizes features using the stored or provided parameters.
    """
    def __init__(self, **kwargs):
        self.means = kwargs.get("means", None)
        self.quats = kwargs.get("quats", None)
        self.scales = kwargs.get("scales", None)
        self.opacities = kwargs.get("opacities", None)
        self.colors = kwargs.get("colors", None)
        self.viewmats = kwargs.get("viewmats", None)
        self.Ks = kwargs.get("Ks", None)
        self.width = kwargs.get("width", None)
        self.height = kwargs.get("height", None)
        self.features = kwargs.get("features", None)
        self.sh_degree = kwargs.get("sh_degree", None)
        print(
            "[WARNING] FeatureRenderer stores references to input arrays, not clones. "
            "Be careful when editing any variable temporarilyâ€”changes will affect the internal state "
            "unless you explicitly clone the data before modifying."
        )

    def render(self, means=None, quats=None, scales=None, opacities=None, colors=None, viewmats=None, Ks=None,width=None,height=None,sh_degree=None, **kwargs):
        # Implement the rendering logic here
        means = self.means if means is None else means
        quats = self.quats if quats is None else quats
        scales = self.scales if scales is None else scales
        opacities = self.opacities if opacities is None else opacities
        colors = self.colors if colors is None else colors
        viewmats = self.viewmats if viewmats is None else viewmats
        Ks = self.Ks if Ks is None else Ks
        width = self.width if width is None else width
        height = self.height if height is None else height
        sh_degree = self.sh_degree if sh_degree is None else sh_degree
        rendered_colors, alphas, meta = rasterization(
            means,
            quats,
            scales,
            opacities,
            colors,
            viewmats=viewmats,
            Ks=Ks,
            width=width,
            height=height,
            sh_degree=sh_degree,
            **kwargs
        )
        return rendered_colors, alphas, meta
    
    def render_features(self, means=None, quats=None, scales=None, opacities=None, features=None, viewmats=None, Ks=None,width=None,height=None, **kwargs):
        means = self.means if means is None else means
        quats = self.quats if quats is None else quats
        scales = self.scales if scales is None else scales
        opacities = self.opacities if opacities is None else opacities
        features = self.features if features is None else features
        viewmats = self.viewmats if viewmats is None else viewmats
        Ks = self.Ks if Ks is None else Ks
        width = self.width if width is None else width
        height = self.height if height is None else height

        rendered_features, alphas, meta = rasterization(
            means,
            quats,
            scales,
            opacities,
            features,
            viewmats=viewmats,
            Ks=Ks,
            width=width,
            height=height,
            **kwargs
        )
        return rendered_features, alphas, meta
    
def to_builtin(obj: Any) -> Any:
    """Recursively convert dataclasses and common non-builtins to YAML-safe types."""
    if is_dataclass(obj):
        return {k: to_builtin(getattr(obj, k)) for k in obj.__dataclass_fields__}
    if isinstance(obj, dict):
        return {to_builtin(k): to_builtin(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple, set)):
        return [to_builtin(v) for v in obj]
    if isinstance(obj, Path):
        return str(obj)
    if isinstance(obj, Enum):
        return obj.value
    if isinstance(obj, np.generic):  # e.g., np.float32(1.0)
        return obj.item()
    return obj
